"""
æ¤œç´¢ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

æ©Ÿèƒ½
- è¤‡æ•°PDFæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã¨å€‹åˆ¥PDFæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ
- æ¤œç´¢çµæœã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã¨éšå±¤è¡¨ç¤º
- å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
- è©³ç´°ãªæ¤œç´¢çµæœã®åˆ†ææƒ…å ±
- ãƒšãƒ¼ã‚¸å†…ã®æ¤œç´¢ãƒã‚¤ãƒ©ã‚¤ãƒˆ
- ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã§ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³
- ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œ
- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ä¸¦ã³æ›¿ãˆæ©Ÿèƒ½
"""

import streamlit as st
from typing import List, Dict, Optional, Union, Any
from datetime import datetime, timedelta
import json
import pandas as pd
from services.search_service import SearchService
from services.document_service import DocumentService
from services.ai_service import AIService
from utils.export_utils import export_manager
import numpy as np
import plotly.express as px

class SearchInterface:
    def __init__(self):
        self.search_service = SearchService()
        self.document_service = DocumentService()
        self.ai_service = AIService()
        self._init_session_state()
    
    def _init_session_state(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
        if "search_history" not in st.session_state:
            st.session_state.search_history = []
        if "current_filters" not in st.session_state:
            st.session_state.current_filters = {}
        if "search_mode" not in st.session_state:
            st.session_state.search_mode = "all"  # "all" or "single"
        if "selected_document" not in st.session_state:
            st.session_state.selected_document = None
        if "dark_mode" not in st.session_state:
            st.session_state.dark_mode = False
    
    def render_search_interface(self):
        """æ¤œç´¢ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®è¡¨ç¤º"""
        # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ
        st.markdown("### æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button(
                "ğŸ“š è¤‡æ•°PDFæ¤œç´¢",
                use_container_width=True,
                type="primary" if st.session_state.search_mode == "all" else "secondary"
            ):
                st.session_state.search_mode = "all"
                st.session_state.selected_document = None
                st.rerun()
        
        with col2:
            if st.button(
                "ğŸ“„ å€‹åˆ¥PDFæ¤œç´¢",
                use_container_width=True,
                type="primary" if st.session_state.search_mode == "single" else "secondary"
            ):
                st.session_state.search_mode = "single"
                st.rerun()
        
        # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸèª¬æ˜
        if st.session_state.search_mode == "all":
            st.info("""
            ğŸ“š **è¤‡æ•°PDFæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰**
            - ã™ã¹ã¦ã®PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å¯¾è±¡ã«æ¤œç´¢
            - é«˜åº¦ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½
            - è¤‡æ•°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¾ãŸãŒã‚‹æ¤œç´¢çµæœã‚’è¡¨ç¤º
            """)
        else:
            st.info("""
            ğŸ“„ **å€‹åˆ¥PDFæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰**
            - é¸æŠã—ãŸ1ã¤ã®PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…ã‚’æ¤œç´¢
            - ãƒšãƒ¼ã‚¸å˜ä½ã§ã®è©³ç´°ãªæ¤œç´¢ãŒå¯èƒ½
            - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸæ¤œç´¢çµæœã‚’è¡¨ç¤º
            """)
        
        # æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form("search_form"):
            # å€‹åˆ¥PDFæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé¸æŠ
            if st.session_state.search_mode == "single":
                documents = self.document_service.get_document_list()
                selected_doc = st.selectbox(
                    "æ¤œç´¢å¯¾è±¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
                    options=[d["file_name"] for d in documents],
                    index=0 if not st.session_state.selected_document else
                    [d["file_name"] for d in documents].index(st.session_state.selected_document)
                )
                st.session_state.selected_document = selected_doc
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                query = st.text_input(
                    "æ¤œç´¢ã‚¯ã‚¨ãƒª",
                    placeholder="æ¤œç´¢ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                    help="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ãƒ•ãƒ¬ãƒ¼ã‚ºã€ã¾ãŸã¯è‡ªç„¶è¨€èªã§æ¤œç´¢ã§ãã¾ã™"
                )
            
            with col2:
                search_type = st.selectbox(
                    "æ¤œç´¢ã‚¿ã‚¤ãƒ—",
                    ["ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰", "ãƒ™ã‚¯ãƒˆãƒ«", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"],
                    help="æ¤œç´¢æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„"
                )
            
            # é«˜åº¦ãªæ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆè¤‡æ•°PDFæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
            if st.session_state.search_mode == "all":
                with st.expander("é«˜åº¦ãªæ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³"):
                    col3, col4 = st.columns(2)
                    
                    with col3:
                        # æ—¥ä»˜ç¯„å›²
                        date_range = st.date_input(
                            "æ—¥ä»˜ç¯„å›²",
                            value=(
                                datetime.now() - timedelta(days=30),
                                datetime.now()
                            ),
                            help="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ—¥æ™‚ã§çµã‚Šè¾¼ã¿"
                        )
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—
                        file_types = st.multiselect(
                            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—",
                            ["PDF", "DOCX", "XLSX", "PPTX"],
                            default=["PDF"],
                            help="æ¤œç´¢å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ"
                        )
                    
                    with col4:
                        # ãƒšãƒ¼ã‚¸ç¯„å›²
                        page_range = st.slider(
                            "ãƒšãƒ¼ã‚¸ç¯„å›²",
                            min_value=1,
                            max_value=1000,
                            value=(1, 100),
                            help="æ¤œç´¢å¯¾è±¡ã®ãƒšãƒ¼ã‚¸ç¯„å›²ã‚’æŒ‡å®š"
                        )
                        
                        # ã‚¿ã‚°
                        tags = st.multiselect(
                            "ã‚¿ã‚°",
                            self._get_available_tags(),
                            help="ã‚¿ã‚°ã§çµã‚Šè¾¼ã¿"
                        )
            
            # æ¤œç´¢ãƒœã‚¿ãƒ³
            search_button = st.form_submit_button("æ¤œç´¢")
        
        # æ¤œç´¢å®Ÿè¡Œ
        if search_button and query:
            filters = None
            if st.session_state.search_mode == "all":
                filters = {
                    "date_range": date_range,
                    "file_types": file_types,
                    "page_range": page_range,
                    "tags": tags
                }
            
            self._execute_search(
                query=query,
                search_type=search_type,
                mode=st.session_state.search_mode,
                target_document=st.session_state.selected_document,
                filters=filters
            )
        
        # æ¤œç´¢å±¥æ­´ã®è¡¨ç¤º
        self._render_search_history()
        
        # æ¤œç´¢çµæœã®è¡¨ç¤º
        if "search_results" in st.session_state:
            self._render_search_results()
    
    def _render_theme_switch(self):
        """ãƒ†ãƒ¼ãƒåˆ‡ã‚Šæ›¿ãˆã‚¹ã‚¤ãƒƒãƒã®è¡¨ç¤º"""
        col1, col2 = st.columns([6, 1])
        
        with col2:
            if st.button("ğŸŒ™" if not st.session_state.dark_mode else "â˜€ï¸"):
                st.session_state.dark_mode = not st.session_state.dark_mode
                st.rerun()
        
        # ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã®é©ç”¨
        if st.session_state.dark_mode:
            st.markdown("""
            <style>
            .stApp {
                background-color: #1E1E1E;
                color: #FFFFFF;
            }
            .stButton>button {
                background-color: #2D2D2D;
                color: #FFFFFF;
            }
            </style>
            """, unsafe_allow_html=True)
    
    def _execute_search(
        self,
        query: str,
        search_type: str,
        mode: str,
        target_document: Optional[str] = None,
        filters: Optional[Dict] = None
    ):
        """æ¤œç´¢ã®å®Ÿè¡Œ"""
        # æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¨­å®š
        search_options = {
            "search_type": search_type.lower(),
            "use_similar_terms": True
        }
        
        # æ¤œç´¢ã®å®Ÿè¡Œ
        results = self.search_service.search(
            query=query,
            mode=mode,
            target_document=target_document,
            filters=filters,
            search_options=search_options,
            top_n=10
        )
        
        # çµæœã®ä¿å­˜
        st.session_state.search_results = results
        st.session_state.current_filters = filters
    
    def _render_search_results(self):
        """æ¤œç´¢çµæœã®è¡¨ç¤ºï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        results = st.session_state.search_results
        
        # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸçµæœè¡¨ç¤º
        if results["metadata"]["mode"] == "single":
            st.markdown(f"### ğŸ“„ {results['metadata']['target_document']} ã®æ¤œç´¢çµæœ")
        else:
            st.markdown("### ğŸ“š è¤‡æ•°PDFæ¤œç´¢çµæœ")
        
        # çµæœã®çµ±è¨ˆæƒ…å ±ã¨åˆ†æ
        self._render_search_analytics(results)
        
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
        self._render_export_options(results)
        
        # æ¤œç´¢çµæœã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã¨è¡¨ç¤º
        grouped_results = self._group_search_results(results["results"])
        self._render_grouped_results(grouped_results)
    
    def _render_search_analytics(self, results: Dict):
        """æ¤œç´¢çµæœã®åˆ†ææƒ…å ±ã®è¡¨ç¤ºï¼ˆè©³ç´°ç‰ˆï¼‰"""
        with st.expander("ğŸ“Š æ¤œç´¢çµæœã®åˆ†æ", expanded=True):
            # åŸºæœ¬çµ±è¨ˆæƒ…å ±
            self._render_basic_stats(results)
            
            # è©³ç´°ãªåˆ†ææƒ…å ±
            tab1, tab2, tab3 = st.tabs([
                "ğŸ“ˆ ã‚¹ã‚³ã‚¢åˆ†æ",
                "ğŸ“‘ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†æ",
                "ğŸ” ãƒãƒƒãƒãƒ³ã‚°åˆ†æ"
            ])
            
            with tab1:
                self._render_score_analysis(results)
            
            with tab2:
                self._render_document_analysis(results)
            
            with tab3:
                self._render_matching_analysis(results)
    
    def _render_basic_stats(self, results: Dict):
        """åŸºæœ¬çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º"""
        col1, col2, col3, col4 = st.columns(4)
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
        doc_matches = {}
        for result in results["results"]:
            doc_name = result["file_name"]
            doc_matches[doc_name] = doc_matches.get(doc_name, 0) + 1
        
        with col1:
            st.metric(
                "æ¤œç´¢å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°",
                len(doc_matches),
                help="ãƒãƒƒãƒã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç·æ•°"
            )
        
        # å¹³å‡ã‚¹ã‚³ã‚¢
        scores = [
            result.get("similarity", result.get("match_score", 0))
            for result in results["results"]
        ]
        avg_score = sum(scores) / len(scores) if scores else 0
        
        with col2:
            st.metric(
                "å¹³å‡ãƒãƒƒãƒã‚¹ã‚³ã‚¢",
                f"{avg_score:.2f}",
                help="å…¨æ¤œç´¢çµæœã®å¹³å‡ã‚¹ã‚³ã‚¢"
            )
        
        # æ¤œç´¢çµæœæ•°
        with col3:
            st.metric(
                "æ¤œç´¢çµæœã®ç·æ•°",
                len(results["results"]),
                help="ãƒãƒƒãƒã—ãŸç®‡æ‰€ã®ç·æ•°"
            )
        
        # é«˜ã‚¹ã‚³ã‚¢ã®çµæœæ•°
        high_scores = len([s for s in scores if s > 0.8])
        
        with col4:
            st.metric(
                "é«˜ã‚¹ã‚³ã‚¢ã®çµæœæ•°",
                high_scores,
                help="ã‚¹ã‚³ã‚¢ãŒ0.8ä»¥ä¸Šã®çµæœæ•°"
            )
    
    def _render_score_analysis(self, results: Dict):
        """ã‚¹ã‚³ã‚¢åˆ†æã®è¡¨ç¤º"""
        scores = [
            result.get("similarity", result.get("match_score", 0))
            for result in results["results"]
        ]
        
        if not scores:
            st.info("ã‚¹ã‚³ã‚¢åˆ†æã‚’è¡Œã†ãŸã‚ã®æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ã‚¹ã‚³ã‚¢åˆ†å¸ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            st.markdown("#### ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
            hist_values = np.histogram(
                scores,
                bins=10,
                range=(0, 1)
            )
            
            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®è¡¨ç¤º
            hist_data = pd.DataFrame({
                "ã‚¹ã‚³ã‚¢ç¯„å›²": [f"{hist_values[1][i]:.1f}-{hist_values[1][i+1]:.1f}" for i in range(len(hist_values[0]))],
                "ä»¶æ•°": hist_values[0]
            })
            st.bar_chart(hist_data.set_index("ã‚¹ã‚³ã‚¢ç¯„å›²"))
        
        with col2:
            # ã‚¹ã‚³ã‚¢çµ±è¨ˆæƒ…å ±
            st.markdown("#### ã‚¹ã‚³ã‚¢çµ±è¨ˆ")
            score_stats = {
                "æœ€é«˜ã‚¹ã‚³ã‚¢": max(scores),
                "æœ€ä½ã‚¹ã‚³ã‚¢": min(scores),
                "å¹³å‡ã‚¹ã‚³ã‚¢": sum(scores) / len(scores),
                "ä¸­å¤®å€¤": sorted(scores)[len(scores)//2],
                "æ¨™æº–åå·®": np.std(scores)
            }
            
            for key, value in score_stats.items():
                st.metric(key, f"{value:.3f}")
    
    def _render_document_analysis(self, results: Dict):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†æã®è¡¨ç¤º"""
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã”ã¨ã®çµ±è¨ˆ
        doc_stats = {}
        for result in results["results"]:
            doc_name = result["file_name"]
            score = result.get("similarity", result.get("match_score", 0))
            
            if doc_name not in doc_stats:
                doc_stats[doc_name] = {
                    "matches": 0,
                    "scores": [],
                    "pages": set(),
                    "matched_terms": set()
                }
            
            doc_stats[doc_name]["matches"] += 1
            doc_stats[doc_name]["scores"].append(score)
            doc_stats[doc_name]["pages"].add(result["page"])
            if "matched_terms" in result:
                doc_stats[doc_name]["matched_terms"].update(result["matched_terms"])
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†æã®è¡¨ç¤º
        st.markdown("#### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ¥åˆ†æ")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
        df_data = []
        for doc_name, stats in doc_stats.items():
            df_data.append({
                "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ": doc_name,
                "ãƒãƒƒãƒæ•°": stats["matches"],
                "å¹³å‡ã‚¹ã‚³ã‚¢": sum(stats["scores"]) / len(stats["scores"]),
                "ãƒãƒƒãƒã—ãŸãƒšãƒ¼ã‚¸æ•°": len(stats["pages"]),
                "ãƒãƒƒãƒã—ãŸç”¨èªæ•°": len(stats["matched_terms"])
            })
        
        df = pd.DataFrame(df_data)
        st.dataframe(
            df.style.background_gradient(subset=["å¹³å‡ã‚¹ã‚³ã‚¢"]),
            use_container_width=True
        )
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥ã®åˆ†æ
        st.markdown("#### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥åˆ†æ")
        doc_types = {}
        for doc_name in doc_stats:
            doc_type = doc_name.split(".")[-1].upper()
            if doc_type not in doc_types:
                doc_types[doc_type] = 0
            doc_types[doc_type] += doc_stats[doc_name]["matches"]
        
        # å††ã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
        fig = px.pie(
            values=list(doc_types.values()),
            names=list(doc_types.keys()),
            title="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥ã®æ¤œç´¢çµæœåˆ†å¸ƒ"
        )
        st.plotly_chart(fig)
    
    def _render_matching_analysis(self, results: Dict):
        """ãƒãƒƒãƒãƒ³ã‚°åˆ†æã®è¡¨ç¤º"""
        # ãƒãƒƒãƒã—ãŸç”¨èªã®åˆ†æ
        term_stats = {}
        similar_term_stats = {}
        
        for result in results["results"]:
            # ãƒãƒƒãƒã—ãŸç”¨èªã®é›†è¨ˆ
            if "matched_terms" in result:
                for term in result["matched_terms"]:
                    term_stats[term] = term_stats.get(term, 0) + 1
            
            # é¡ä¼¼èªã®é›†è¨ˆ
            if "similar_terms" in result:
                for term in result["similar_terms"]:
                    similar_term_stats[term] = similar_term_stats.get(term, 0) + 1
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ãƒãƒƒãƒã—ãŸç”¨èªã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            st.markdown("#### ãƒãƒƒãƒã—ãŸç”¨èªTOP10")
            if term_stats:
                term_df = pd.DataFrame([
                    {"ç”¨èª": term, "å‡ºç¾å›æ•°": count}
                    for term, count in sorted(
                        term_stats.items(),
                        key=lambda x: x[1],
                        reverse=True
                    )[:10]
                ])
                st.bar_chart(term_df.set_index("ç”¨èª"))
            else:
                st.info("ãƒãƒƒãƒã—ãŸç”¨èªãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        with col2:
            # é¡ä¼¼èªã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            st.markdown("#### ä½¿ç”¨ã•ã‚ŒãŸé¡ä¼¼èªTOP10")
            if similar_term_stats:
                similar_term_df = pd.DataFrame([
                    {"é¡ä¼¼èª": term, "ä½¿ç”¨å›æ•°": count}
                    for term, count in sorted(
                        similar_term_stats.items(),
                        key=lambda x: x[1],
                        reverse=True
                    )[:10]
                ])
                st.bar_chart(similar_term_df.set_index("é¡ä¼¼èª"))
            else:
                st.info("ä½¿ç”¨ã•ã‚ŒãŸé¡ä¼¼èªãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        # ãƒãƒƒãƒãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
        st.markdown("#### ãƒãƒƒãƒãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ")
        pattern_stats = {
            "å®Œå…¨ä¸€è‡´": 0,
            "éƒ¨åˆ†ä¸€è‡´": 0,
            "é¡ä¼¼èªãƒãƒƒãƒ": 0
        }
        
        for result in results["results"]:
            if result.get("match_type") == "exact":
                pattern_stats["å®Œå…¨ä¸€è‡´"] += 1
            elif result.get("match_type") == "partial":
                pattern_stats["éƒ¨åˆ†ä¸€è‡´"] += 1
            elif result.get("match_type") == "similar":
                pattern_stats["é¡ä¼¼èªãƒãƒƒãƒ"] += 1
        
        # æ£’ã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
        pattern_df = pd.DataFrame([
            {"ãƒ‘ã‚¿ãƒ¼ãƒ³": k, "ä»¶æ•°": v}
            for k, v in pattern_stats.items()
        ])
        st.bar_chart(pattern_df.set_index("ãƒ‘ã‚¿ãƒ¼ãƒ³"))
    
    def _group_search_results(self, results: List[Dict]) -> Dict[str, Dict]:
        """æ¤œç´¢çµæœã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–"""
        grouped = {}
        
        for result in results:
            doc_name = result["file_name"]
            page = result["page"]
            
            if doc_name not in grouped:
                grouped[doc_name] = {
                    "total_matches": 0,
                    "avg_score": 0,
                    "pages": {}
                }
            
            if page not in grouped[doc_name]["pages"]:
                grouped[doc_name]["pages"][page] = []
            
            grouped[doc_name]["pages"][page].append(result)
            grouped[doc_name]["total_matches"] += 1
            
            # ã‚¹ã‚³ã‚¢ã®æ›´æ–°
            scores = [
                r.get("similarity", r.get("match_score", 0))
                for r in grouped[doc_name]["pages"][page]
            ]
            grouped[doc_name]["avg_score"] = sum(scores) / len(scores)
        
        return grouped
    
    def _render_grouped_results(self, grouped_results: Dict[str, Dict]):
        """ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸæ¤œç´¢çµæœã®è¡¨ç¤º"""
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ä¸¦ã³æ›¿ãˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
        with st.expander("ğŸ” æ¤œç´¢çµæœã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ä¸¦ã³æ›¿ãˆ", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                # ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                min_score = st.slider(
                    "æœ€å°ã‚¹ã‚³ã‚¢",
                    min_value=0.0,
                    max_value=1.0,
                    value=0.3,
                    step=0.1,
                    help="ã“ã®ã‚¹ã‚³ã‚¢ä»¥ä¸Šã®çµæœã®ã¿ã‚’è¡¨ç¤º"
                )
                
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                doc_types = self._get_document_types(grouped_results)
                selected_types = st.multiselect(
                    "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—",
                    options=doc_types,
                    default=doc_types,
                    help="è¡¨ç¤ºã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’é¸æŠ"
                )
            
            with col2:
                # ä¸¦ã³æ›¿ãˆåŸºæº–
                sort_by = st.selectbox(
                    "ä¸¦ã³æ›¿ãˆåŸºæº–",
                    options=[
                        "ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„é †ï¼‰",
                        "ã‚¹ã‚³ã‚¢ï¼ˆä½ã„é †ï¼‰",
                        "ãƒãƒƒãƒæ•°ï¼ˆå¤šã„é †ï¼‰",
                        "ãƒãƒƒãƒæ•°ï¼ˆå°‘ãªã„é †ï¼‰",
                        "ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ˜‡é †ï¼‰",
                        "ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆé™é †ï¼‰",
                        "æ›´æ–°æ—¥æ™‚ï¼ˆæ–°ã—ã„é †ï¼‰",
                        "æ›´æ–°æ—¥æ™‚ï¼ˆå¤ã„é †ï¼‰"
                    ],
                    help="æ¤œç´¢çµæœã®ä¸¦ã³æ›¿ãˆæ–¹æ³•ã‚’é¸æŠ"
                )
                
                # è¡¨ç¤ºä»¶æ•°
                results_per_page = st.number_input(
                    "è¡¨ç¤ºä»¶æ•°",
                    min_value=5,
                    max_value=100,
                    value=10,
                    step=5,
                    help="1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®è¡¨ç¤ºä»¶æ•°"
                )
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ä¸¦ã³æ›¿ãˆã®é©ç”¨
        filtered_docs = self._apply_result_filters(
            grouped_results,
            min_score=min_score,
            selected_types=selected_types
        )
        
        sorted_docs = self._sort_results(
            filtered_docs,
            sort_by=sort_by
        )
        
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
        total_pages = (len(sorted_docs) + results_per_page - 1) // results_per_page
        if total_pages > 1:
            current_page = st.selectbox(
                "ãƒšãƒ¼ã‚¸",
                options=range(1, total_pages + 1),
                format_func=lambda x: f"ãƒšãƒ¼ã‚¸ {x}/{total_pages}"
            )
            start_idx = (current_page - 1) * results_per_page
            end_idx = start_idx + results_per_page
            display_docs = sorted_docs[start_idx:end_idx]
        else:
            display_docs = sorted_docs
        
        # çµæœã®è¡¨ç¤º
        for doc_name, doc_data in display_docs:
            with st.expander(
                f"ğŸ“„ {doc_name} "
                f"(ãƒãƒƒãƒæ•°: {doc_data['total_matches']}, "
                f"å¹³å‡ã‚¹ã‚³ã‚¢: {doc_data['avg_score']:.2f})",
                expanded=True
            ):
                # ãƒšãƒ¼ã‚¸ã”ã¨ã®çµæœ
                for page, page_results in sorted(doc_data["pages"].items()):
                    st.markdown(f"#### ãƒšãƒ¼ã‚¸ {page}")
                    
                    for result in page_results:
                        self._render_enhanced_result_preview(result)
    
    def _get_document_types(self, grouped_results: Dict[str, Dict]) -> List[str]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®ä¸€è¦§ã‚’å–å¾—"""
        doc_types = set()
        for doc_name in grouped_results:
            doc_type = doc_name.split(".")[-1].upper()
            doc_types.add(doc_type)
        return sorted(list(doc_types))
    
    def _apply_result_filters(
        self,
        grouped_results: Dict[str, Dict],
        min_score: float,
        selected_types: List[str]
    ) -> List[tuple]:
        """æ¤œç´¢çµæœã«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨"""
        filtered = []
        
        for doc_name, doc_data in grouped_results.items():
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            doc_type = doc_name.split(".")[-1].upper()
            if doc_type not in selected_types:
                continue
            
            # ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if doc_data["avg_score"] < min_score:
                continue
            
            filtered.append((doc_name, doc_data))
        
        return filtered
    
    def _sort_results(
        self,
        filtered_docs: List[tuple],
        sort_by: str
    ) -> List[tuple]:
        """æ¤œç´¢çµæœã‚’æŒ‡å®šã•ã‚ŒãŸåŸºæº–ã§ä¸¦ã³æ›¿ãˆ"""
        if sort_by == "ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„é †ï¼‰":
            return sorted(
                filtered_docs,
                key=lambda x: x[1]["avg_score"],
                reverse=True
            )
        elif sort_by == "ã‚¹ã‚³ã‚¢ï¼ˆä½ã„é †ï¼‰":
            return sorted(
                filtered_docs,
                key=lambda x: x[1]["avg_score"]
            )
        elif sort_by == "ãƒãƒƒãƒæ•°ï¼ˆå¤šã„é †ï¼‰":
            return sorted(
                filtered_docs,
                key=lambda x: x[1]["total_matches"],
                reverse=True
            )
        elif sort_by == "ãƒãƒƒãƒæ•°ï¼ˆå°‘ãªã„é †ï¼‰":
            return sorted(
                filtered_docs,
                key=lambda x: x[1]["total_matches"]
            )
        elif sort_by == "ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ˜‡é †ï¼‰":
            return sorted(filtered_docs, key=lambda x: x[0])
        elif sort_by == "ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆé™é †ï¼‰":
            return sorted(filtered_docs, key=lambda x: x[0], reverse=True)
        elif sort_by == "æ›´æ–°æ—¥æ™‚ï¼ˆæ–°ã—ã„é †ï¼‰":
            return sorted(
                filtered_docs,
                key=lambda x: self.document_service.get_document_metadata(x[0])["last_modified"],
                reverse=True
            )
        else:  # "æ›´æ–°æ—¥æ™‚ï¼ˆå¤ã„é †ï¼‰"
            return sorted(
                filtered_docs,
                key=lambda x: self.document_service.get_document_metadata(x[0])["last_modified"]
            )
    
    def _render_enhanced_result_preview(self, result: Dict):
        """å¼·åŒ–ã•ã‚ŒãŸæ¤œç´¢çµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º"""
        # ã‚¹ã‚³ã‚¢ã«åŸºã¥ãè‰²åˆ†ã‘
        score = result.get("similarity", result.get("match_score", 0))
        score_color = (
            "green" if score > 0.8
            else "orange" if score > 0.5
            else "red"
        )
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
        st.markdown(f"""
        <style>
        .result-preview {{
            border-left: 4px solid {score_color};
            padding: 10px;
            margin: 10px 0;
            background-color: #f8f9fa;
            border-radius: 4px;
        }}
        .context-text {{
            font-family: monospace;
            background-color: #e9ecef;
            padding: 8px;
            border-radius: 4px;
            margin: 5px 0;
        }}
        .matched-text {{
            font-family: monospace;
            background-color: #fff3cd;
            padding: 8px;
            border-radius: 4px;
            margin: 5px 0;
        }}
        .metadata-grid {{
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 10px;
            margin: 10px 0;
        }}
        </style>
        """, unsafe_allow_html=True)
        
        # çµæœã®è¡¨ç¤º
        st.markdown(
            '<div class="result-preview">',
            unsafe_allow_html=True
        )
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            st.markdown(f"**ğŸ“„ {result['file_name']}**")
        with col2:
            st.markdown(f"**ãƒšãƒ¼ã‚¸:** {result['page']}")
        with col3:
            st.markdown(f"**ã‚¹ã‚³ã‚¢:** {score:.2f}")
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¡¨ç¤ºï¼ˆæ”¹å–„ç‰ˆï¼‰
        if "context" in result:
            st.markdown("**å‰å¾Œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ**")
            context = result["context"]
            query = st.session_state.get("last_query", "")
            
            if query:
                # ã‚¯ã‚¨ãƒªã®å‰å¾Œã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
                parts = context.split(query)
                if len(parts) > 1:
                    # å‰ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                    st.markdown(
                        f'<div class="context-text">{parts[0]}</div>',
                        unsafe_allow_html=True
                    )
                    # ãƒãƒƒãƒã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
                    st.markdown(
                        f'<div class="matched-text">{query}</div>',
                        unsafe_allow_html=True
                    )
                    # å¾Œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                    st.markdown(
                        f'<div class="context-text">{parts[1]}</div>',
                        unsafe_allow_html=True
                    )
                else:
                    st.markdown(
                        f'<div class="context-text">{context}</div>',
                        unsafe_allow_html=True
                    )
        
        # ãƒãƒƒãƒã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®è¡¨ç¤ºï¼ˆæ”¹å–„ç‰ˆï¼‰
        st.markdown("**ãƒãƒƒãƒã—ãŸãƒ†ã‚­ã‚¹ãƒˆ**")
        text = result["text"]
        query = st.session_state.get("last_query", "")
        similar_terms = result.get("similar_terms", [])
        
        if query or similar_terms:
            highlighted_text = text
            # ã‚¯ã‚¨ãƒªã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            if query:
                highlighted_text = highlighted_text.replace(
                    query,
                    f'<span style="background-color: #ffd700; padding: 2px;">{query}</span>'
                )
            # é¡ä¼¼èªã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            for term in similar_terms:
                highlighted_text = highlighted_text.replace(
                    term,
                    f'<span style="background-color: #90ee90; padding: 2px;">{term}</span>'
                )
            st.markdown(
                f'<div class="matched-text">{highlighted_text}</div>',
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                f'<div class="matched-text">{text}</div>',
                unsafe_allow_html=True
            )
        
        # è©³ç´°æƒ…å ±ã®è¡¨ç¤ºï¼ˆæ”¹å–„ç‰ˆï¼‰
        with st.expander("ğŸ“‹ è©³ç´°æƒ…å ±"):
            st.markdown('<div class="metadata-grid">', unsafe_allow_html=True)
            
            # åŸºæœ¬æƒ…å ±
            st.markdown("**åŸºæœ¬æƒ…å ±**")
            st.json({
                "ãƒ•ã‚¡ã‚¤ãƒ«å": result["file_name"],
                "ãƒšãƒ¼ã‚¸": result["page"],
                "ã‚¹ã‚³ã‚¢": f"{score:.2f}",
                "ã‚¿ã‚¤ãƒ—": result.get("type", "unknown"),
                "æ›´æ–°æ—¥æ™‚": result.get("last_modified", "ä¸æ˜")
            })
            
            # ãƒãƒƒãƒæƒ…å ±
            if "matched_terms" in result or "similar_terms" in result:
                st.markdown("**ãƒãƒƒãƒæƒ…å ±**")
                match_info = {}
                if "matched_terms" in result:
                    match_info["ãƒãƒƒãƒã—ãŸç”¨èª"] = result["matched_terms"]
                if "similar_terms" in result:
                    match_info["é¡ä¼¼èª"] = result["similar_terms"]
                st.json(match_info)
            
            # è¿½åŠ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            if "metadata" in result:
                st.markdown("**è¿½åŠ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**")
                st.json(result["metadata"])
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("ğŸ“„ PDFã§è¡¨ç¤º", key=f"view_{result['file_name']}_{result['page']}"):
                self._show_pdf_preview(result)
        with col2:
            if st.button("ğŸ“‹ ã‚³ãƒ”ãƒ¼", key=f"copy_{result['file_name']}_{result['page']}"):
                self._copy_to_clipboard(result)
        with col3:
            if st.button("â­ ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯", key=f"bookmark_{result['file_name']}_{result['page']}"):
                self._add_to_bookmarks(result)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    def _show_pdf_preview(self, result: Dict):
        """PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è¡¨ç¤º"""
        try:
            pdf_data = self.document_service.get_page_preview(
                file_name=result["file_name"],
                page=result["page"]
            )
            st.image(pdf_data, caption=f"{result['file_name']} - ãƒšãƒ¼ã‚¸ {result['page']}")
        except Exception as e:
            st.error(f"PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    def _copy_to_clipboard(self, result: Dict):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼"""
        text = result.get("text", "")
        st.write("ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼")
        st.session_state["clipboard"] = text
    
    def _add_to_bookmarks(self, result: Dict):
        """æ¤œç´¢çµæœã‚’ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã«è¿½åŠ """
        if "bookmarks" not in st.session_state:
            st.session_state.bookmarks = []
        
        bookmark = {
            "file_name": result["file_name"],
            "page": result["page"],
            "text": result.get("text", ""),
            "added_at": datetime.now().isoformat()
        }
        
        st.session_state.bookmarks.append(bookmark)
        st.write("ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã«è¿½åŠ ã—ã¾ã—ãŸï¼")
    
    def _render_export_options(self, results: Dict):
        """ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¡¨ç¤º"""
        with st.expander("ğŸ“¥ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                export_format = st.selectbox(
                    "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼",
                    ["CSV", "Excel", "PDF"],
                    key="export_format"
                )
            
            with col2:
                export_options = st.multiselect(
                    "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆé …ç›®",
                    ["åŸºæœ¬æƒ…å ±", "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ", "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿", "åˆ†ææƒ…å ±"],
                    default=["åŸºæœ¬æƒ…å ±", "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"]
                )
            
            if st.button("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", key="export_button"):
                export_data = self.search_service.export_results(
                    results=results["results"],
                    format=export_format.lower(),
                    options=export_options
                )
                
                st.download_button(
                    label=f"{export_format}ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=export_data,
                    file_name=f"search_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{export_format.lower()}",
                    mime=f"application/{export_format.lower()}"
                )
    
    def _render_search_history(self):
        """æ¤œç´¢å±¥æ­´ã®è¡¨ç¤º"""
        if st.session_state.search_history:
            with st.expander("æ¤œç´¢å±¥æ­´"):
                for history in st.session_state.search_history[-5:]:
                    if st.button(
                        f"{history['query']} ({history['timestamp']})",
                        key=f"history_{history['timestamp']}"
                    ):
                        self._execute_search(
                            query=history["query"],
                            search_type=history.get("search_type", "hybrid"),
                            filters=history.get("filters", {})
                        )
    
    def _get_available_tags(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚°ã®å–å¾—"""
        # å®Ÿè£…ã¯æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã«ä¾å­˜
        return ["é‡è¦", "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¸ˆã¿", "è¦ç¢ºèª", "å®Œäº†"]
    
    def render_file_upload(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®è¡¨ç¤º"""
        st.write("### ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        # ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã‚¨ãƒªã‚¢
        uploaded_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã¾ãŸã¯ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["pdf", "docx", "xlsx", "pptx"],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            with st.expander("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³"):
                folder_path = st.text_input(
                    "ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹",
                    value="/",
                    help="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹"
                )
                
                tags = st.multiselect(
                    "ã‚¿ã‚°",
                    self._get_available_tags(),
                    help="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ä»˜ã‘ã‚‹ã‚¿ã‚°"
                )
                
                metadata = st.text_area(
                    "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ (JSONå½¢å¼)",
                    value="{}",
                    help="è¿½åŠ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§å…¥åŠ›"
                )
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            if st.button("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"):
                try:
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è§£æ
                    metadata_dict = json.loads(metadata)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                    files = [
                        {
                            "file_data": file.getvalue(),
                            "file_name": file.name
                        }
                        for file in uploaded_files
                    ]
                    
                    results = self.document_service.upload_multiple_documents(
                        files=files,
                        folder_path=folder_path,
                        tags={file.name: tags for file in uploaded_files},
                        metadata={file.name: metadata_dict for file in uploaded_files}
                    )
                    
                    # çµæœã®è¡¨ç¤º
                    for result in results:
                        if result["status"] == "success":
                            st.success(f"{result['file_name']} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸ")
                        else:
                            st.error(f"{result['file_name']} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {result['error']}")
                
                except json.JSONDecodeError:
                    st.error("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®JSONå½¢å¼ãŒä¸æ­£ã§ã™")
                except Exception as e:
                    st.error(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}") 